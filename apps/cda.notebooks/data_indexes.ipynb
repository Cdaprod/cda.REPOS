{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': [{'class': 'BlogPost',\n",
       "   'description': 'Blog post from the Weaviate website.',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'text2vec-openai': {'model': 'ada',\n",
       "     'modelVersion': '002',\n",
       "     'type': 'text',\n",
       "     'vectorizeClassName': True}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['text'],\n",
       "     'description': 'Content from the blog post',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'content',\n",
       "     'tokenization': 'word'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-openai'},\n",
       "  {'class': 'Blogs_index_Node',\n",
       "   'description': 'Class for Blogs_index_Node',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['text'],\n",
       "     'description': 'Text property',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'name': 'text',\n",
       "     'tokenization': 'whitespace'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'The ref_doc_id of the Node',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'name': 'ref_doc_id',\n",
       "     'tokenization': 'whitespace'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'node_info (in JSON)',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'name': 'node_info',\n",
       "     'tokenization': 'whitespace'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'The relationships of the node (in JSON)',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'name': 'relationships',\n",
       "     'tokenization': 'whitespace'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'none'}]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weaviate \n",
    "\n",
    "client = weaviate.Client(\n",
    "  url=\"https://llama2-example-tmf15eda.weaviate.network\",  # URL to Weaviate instance\n",
    ")\n",
    "\n",
    "client.schema.get()  # Get the schema to test connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Schema "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blog Post Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema was created.\n"
     ]
    }
   ],
   "source": [
    "blog_post_schema = {\n",
    "   \"classes\": [\n",
    "       {\n",
    "           \"class\": \"BlogPost\",\n",
    "           \"description\": \"Blog post from the Weaviate website.\",\n",
    "           \"vectorizer\": \"text2vec-openai\",\n",
    "           \"properties\": [\n",
    "               {\n",
    "                  \"name\": \"Content\",\n",
    "                  \"dataType\": [\"text\"],\n",
    "                  \"description\": \"Content from the blog post\",\n",
    "               }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "client.schema.delete_all()\n",
    "\n",
    "client.schema.create(blog_post_schema)\n",
    "\n",
    "print(\"Schema was created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podcast Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema was created.\n"
     ]
    }
   ],
   "source": [
    "podcast_schema = {\n",
    "   \"classes\": [\n",
    "       {\n",
    "           \"class\": \"Podcast\",\n",
    "           \"description\": \"Weaviate podcast\",\n",
    "           \"vectorizer\": \"text2vec-openai\",\n",
    "           \"properties\": [\n",
    "               {\n",
    "                  \"name\": \"Content\",\n",
    "                  \"dataType\": [\"text\"],\n",
    "                  \"description\": \"Content from the podcasts.\",\n",
    "               }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "client.schema.create(podcast_schema)\n",
    "\n",
    "print(\"Schema was created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "# load the blogs in using the reader\n",
    "blogs = SimpleDirectoryReader('./data').load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload podcasts (sticking to the release podcasts only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pkg_resources/_vendor/jaraco/text/__init__.py:593: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.11/site-packages/llama_index/readers/llamahub_modules/youtube_transcript/requirements.txt' mode='r' encoding='UTF-8'>\n",
      "  for item in lines:\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/local/lib/python3.11/site-packages/youtube_transcript_api/_api.py:132: ResourceWarning: unclosed <ssl.SSLSocket fd=79, family=30, type=1, proto=0, laddr=('2601:182:ca00:6410:c1e5:322c:7bf2:7d99', 59947, 0, 0), raddr=('2607:f8b0:4006:80c::200e', 443, 0, 0)>\n",
      "  return cls.list_transcripts(video_id, proxies, cookies).find_transcript(languages).fetch()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/local/lib/python3.11/site-packages/youtube_transcript_api/_api.py:132: ResourceWarning: unclosed <ssl.SSLSocket fd=79, family=30, type=1, proto=0, laddr=('2601:182:ca00:6410:c1e5:322c:7bf2:7d99', 59951, 0, 0), raddr=('2607:f8b0:4006:80c::200e', 443, 0, 0)>\n",
      "  return cls.list_transcripts(video_id, proxies, cookies).find_transcript(languages).fetch()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/local/lib/python3.11/site-packages/youtube_transcript_api/_api.py:132: ResourceWarning: unclosed <ssl.SSLSocket fd=79, family=30, type=1, proto=0, laddr=('2601:182:ca00:6410:c1e5:322c:7bf2:7d99', 59957, 0, 0), raddr=('2607:f8b0:4006:80c::200e', 443, 0, 0)>\n",
      "  return cls.list_transcripts(video_id, proxies, cookies).find_transcript(languages).fetch()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/local/lib/python3.11/site-packages/youtube_transcript_api/_api.py:132: ResourceWarning: unclosed <ssl.SSLSocket fd=79, family=30, type=1, proto=0, laddr=('2601:182:ca00:6410:45d9:5e2:3d9b:5eaf', 59961, 0, 0), raddr=('2607:f8b0:4006:80c::200e', 443, 0, 0)>\n",
      "  return cls.list_transcripts(video_id, proxies, cookies).find_transcript(languages).fetch()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from llama_index import download_loader\n",
    "\n",
    "YoutubeTranscriptReader = download_loader(\"YoutubeTranscriptReader\")\n",
    "\n",
    "loader = YoutubeTranscriptReader()\n",
    "podcasts = loader.load_data(ytlinks=['https://www.youtube.com/watch?v=xk28RMhRy1U&t=2302s', 'https://www.youtube.com/watch?v=Du6IphCcCec', \n",
    "'https://www.youtube.com/watch?v=Q7f2JeuMN7E&t=578s', 'https://www.youtube.com/watch?v=nSCUk5pHXlo&t=22s'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blogs Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores import WeaviateVectorStore\n",
    "from llama_index import VectorStoreIndex, ListIndex\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "\n",
    "vector_store = WeaviateVectorStore(weaviate_client=client, class_prefix=\"Blogs_index\")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "blogs_index = VectorStoreIndex.from_documents(blogs, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podcast Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vector_store = WeaviateVectorStore(weaviate_client=client, class_prefix=\"Podcasts_index\")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "podcasts_index = VectorStoreIndex.from_documents(podcasts, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meeting Notes Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "meetingNotes = SimpleDirectoryReader('./meeting-notes').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SimpleNodeParser\n",
    "\n",
    "parser = SimpleNodeParser()\n",
    "nodes = parser.get_nodes_from_documents(meetingNotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, ListIndex\n",
    "\n",
    "\n",
    "notes_index = ListIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of each Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogs_index_summary = \"\"\"\n",
    "This index contains all of the blog posts that are on Weaviate.io.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcasts_index_summary = \"\"\"\n",
    "This index contains the Weaviate podcasts about new releases.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_index_summary = \"\"\"\n",
    "This index contains notes from a client named Connor.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_summaries = [blogs_index_summary, podcasts_index_summary, meeting_index_summary]\n",
    "blogs_index.set_index_id(\"blogs_index\")\n",
    "podcasts_index.set_index_id(\"podcasts_index\")\n",
    "notes_index.set_index_id(\"notes_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.composability import ComposableGraph\n",
    "\n",
    "graph = ComposableGraph.from_indices(\n",
    "    ListIndex,\n",
    "    [blogs_index, podcasts_index, notes_index],\n",
    "    index_summaries=index_summaries\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_query_engines = {\n",
    "    graph.root_id: graph.root_index.as_query_engine(\n",
    "        retriever_mode=\"default\" )\n",
    "}\n",
    "\n",
    "query_engine = graph.as_query_engine(\n",
    "    custom_query_engines=custom_query_engines,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multi-tenancy is a software architecture that allows multiple tenants to use the same instance of an application, with each tenant having their own isolated data and resources. It is an important feature for Connor's application because it allows them to scale to millions of tenants, while still providing each tenant with their own isolated environment. This ensures that each tenant's data is secure and that their experience is tailored to their specific needs. Additionally, multi-tenancy allows for access isolation, speed, easy on and offboarding, resource boundaries, cost-efficiency, GDPR-compliant deletes with one command, efficient querying, and massive scale.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What is multi-tenancy? Why is it an important feature for Connor's application?\"\n",
    ")\n",
    "\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Source (Doc id: 7b6f1041-f4b3-448d-98f1-dcc51ddef203): Multi-tenancy is a feature that allows multiple distinct users or user groups to be served from a...\n",
      "\n",
      "> Source (Doc id: 92c81eb0-661b-40bd-ac2a-d69ee0060cb5): Multi-tenancy is a feature that allows an application to serve multiple tenants (users or organiz...\n",
      "\n",
      "> Source (Doc id: 03be7386-0ab1-4d55-8264-48352bcf674f): Multi-tenancy is a software architecture that allows multiple tenants to use the same instance of...\n",
      "\n",
      "> Source (Doc id: eb7879c8-16c2-40a1-b1e0-7049a7c6791f): title: Multi-Tenancy Vector Search with millions of tenants\n",
      "\n",
      "\n",
      "Large-scale setups were always a gr...\n",
      "\n",
      "> Source (Doc id: f62822a9-c7a0-4f92-8550-17bc39c127a2): would typically query less than 0.01% of the index. What a waste of resources. Additionally, drop...\n",
      "\n",
      "> Source (Doc id: 46284cbd-ff6f-4fb8-9bbc-d512fdf31ca6): testing you do this before any\n",
      "release but I think\n",
      "for for this release this was the most\n",
      "amount ...\n",
      "\n",
      "> Source (Doc id: f50e8f31-3f89-4428-b2d9-5cdbdf3e6a24): of doing a lot of\n",
      "overhead for essentially you just wanted\n",
      "to end up with 10 charts but you could...\n",
      "\n",
      "> Source (Doc id: af92b925-b100-4b4b-9cb3-53154b9000eb): Meeting Notes\n",
      "Date: July 13, 2023\n",
      "Attendees: Connor (C), Weaviate (W)\n",
      "\n",
      "Agenda: Exploring Multi-Te...\n"
     ]
    }
   ],
   "source": [
    "print(response.get_formatted_sources())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
